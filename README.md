# Music Analytics and Curation Portfolio 2619532


#  Week 1    


>**Task 2: Identify a theme for your dataset**


The theme i have chosen for my data set will focus around the composer of Tchaichovsky within the Romantic Period. With a particular focus on the first movement of Tchaickovsky's violin concerto in D major.

### Musical Scores
  
  The sheet music for this piece can be found on many sheet music platforms. For the full orchestral score this can be found on IMSLP. Here there are mnay different versions of the score uploaded by different users. These scores range in levels of quality. The violin and piano score can be found on a range of different websites including MuseScore and Free violin sheet music. Hence this Piece's sheet music is extremely accessible and free. The physical copy of the sheet music can also be purchased on many popular music sheet music sites such as Music Room.
  
### Audio Recording 
 
 As it is such a well known piece the audio recording is available on most streaming platforms including Spotify and Youtube. There are many different versions of an audio recording. The audio file can be downloaded also from IMSLP. On IMSLP multiple different MP3 files can be downloaded. these recordings range from recordings on the full piece and also the option to download the individual movement. 

### Metadata and Descriptive data
 For descriptive and metadata, IMSLP does include different forms of metadata in the general information Section. Dependant on the Arrangement, Composer, Arrranger, publisher info, opus number, number of movements, date of composition, average duration,and composer time period and style. However information regarding this piece can be sourced from many website and sources. 

 >**Task 3: Challenges Working With Music and Music Related Data Within My Chosen Project**

### Musical Scores 
Diffuculties that arose within the musical scores came within the qualities of these scores. IMSLP offer many different verions of scores, these come in the form of scanned by users of IMSLP. Within the collection of scores within IMSLP many ranged in how they were uploaded, some were scannded as newly transcribed versions so appeared on a white background and were clear to see, however some where scanned from original scores so on off-white coloured backrounds, this leads to many of the notes being hard to ideantify. Only scans of original manuscripts are available, and only available in PDF form with no availabity of music software notated sheet music. 

### Audio Recording 
Similar issues to the musical scores arose within the audio recordings. This included again a range of quality in the recordings with all including noises that distort the sound of the music audio, by miscellaneous recording noises such as crackling.

### Descrptive Data 
 Issues that arose from this data is that the imformation accuracy depended on the arrangement and the version. For example the full orchestral one or it has also been arranged for piano, which would change some of the provided descriptive data. This is due to the mostly lack of standardisation within music meta data accross different musical forms, for example different technical meta data is different from physical music forms such as a CDs and vinyls compared to digital files.




# Week 2

See below my edited version of a violin and piano transcription of the opening section of my chosen piece. When uploaded on MuseScore there were a number of issues faced. The opening scene was not massively effected, However when the piece moved into more intricate notes and articultions, this is were many errors ocurred. This ranged from the pitch and rhythm of the notes. Within the base line of the piece there was a change of clef which also was not transcribed by the OMR engine. Any grace notes or ornamants of such were also misssing from the transcription 

 This can be accessed through the link [here](https://github.com/rkirk903/MCA-2024/blob/master/MusicAnalyticsScore2619532K.mscz) 
 
## Example of my edited transcription
 
<img src="https://github.com/user-attachments/assets/1a3746b0-9073-44dd-8e0c-62b892b0f0c4" alt="Piano Roll" width="400" height="500">


 
 
# Week 3

>**Task 1:  Export the score you created last week to MusicXML and MEI**

See my linked [MEI](https://github.com/rkirk903/MCA-2024/blob/master/data/week3musicxml.mei) and [MusicXML](https://github.com/rkirk903/MCA-2024/blob/master/data/week3musicxml.xml)

> **Task 2: Render your MEI file using Verovio in GitHub.**


[Link To My Verovio Webpage](https://rkirk903.github.io/MCA-2024/verovio.html)

<iframe src="https://rkirk903.github.io/MCA-2024/verovio.html" width="1000" height="800"></iframe>










# Week 4
> **Task 1: Generate a jSymbolic analysis of your piece (Remember, jSymbolic is located in the directory:  C:\Program Files\Jsymbolic)When Generating a JSymbolic anylsis of my piece, i gained the following information**

- Range : 60

* Mean Pitch: 62.04

+ Most Common Pitch Class : 45

- Last Pitch : 67

* Most Common rhythmic value : 0.5

  This can also be viewed in my attatched [CSV](https://github.com/rkirk903/MCA-2024/blob/master/week4values.csv)

> **Task 2: Generate a piano roll and pitch histogram of your piece using music21.**


See below my piano roll and other visual graphs generated using music 21 :

## Piano Roll


<img src="https://github.com/user-attachments/assets/a216bca1-7734-4610-9237-66e7d3a6933b" alt="Piano Roll" width="500" height="400">



## Pitch Histogram


<img src="https://github.com/user-attachments/assets/6316fcca-2ad1-4f39-8a06-f2ad0d76d0e2" alt="histogram" width="500" height="500">


## Scatter Plot of Pitches 


<img src="https://github.com/user-attachments/assets/aa1a1634-95fc-4c92-b84b-89dc2599a6ad" alt="scatter plot" width="500" height="500">



# Week 5
> **Task 1: Create a metadata schema of at least 5 elements, including title, artist, publisher, and at least two others of your choice.**

* Title : Violin Concerto in D major
- Composer : Tchaikhovsky
+ Publisher : P Juregenson 
* Date : 1888
- Location : Moscow
- Encoded by: Ria Kirkwoood 



> **Task 2: Modify your MEI document according to the schema that you have created. Where possible, enrich your data by linking it to existing authorities**



Access my edited MEI document here [Week 5 MEI](https://github.com/rkirk903/MCA-2024/blob/master/data/Week5Lab.mei)



# Week 7
 > **Task 1: Modify your MEI document according to the schema that you have created. Where possible, enrich your data by linking it to existing authorities**

See below my attached uptated MEI file where i have updated the meta data to include genre classsifications and specific liscensing data. 
Download my further edited MEI file [here](https://github.com/rkirk903/MCA-2024/blob/master/data/week7)

 > **Task 2: Render your revised MEI metadata along with your score on an HTML page.**

See my linked HTML page,[here](https://rkirk903.github.io/MCA-2024/metaRAW.html)



<iframe src="https://rkirk903.github.io/MCA-2024/metaRAW.html" width="1000" height="800"></iframe>






> **Discuss why you have made the choices you made.**

* My chosen piece of music is within the public domain and so all transcriptions should remain in the public domain for the fair use of anyone , It is in the public domain as Tchaikovsky - the composer- has been dead for longer that 50 years. The use of this piece is only for the use of this project for educational and research purposes.

- I classified the genre under classical and Romantic, as I believe these genres accurately describe the music and that people looking for this piece would use those key words in their search.







# Week 8 



> **Task 1: Find and describe 3 audio tracks relating to your theme**
The three tracks I have chosen are within my theme of orchestral pieces written during the romantic period and composed by tchaickovsky. See Table Below for the technical and non technical meta data of each recording: 

| Title | Artist | Composer | Copyright Domain | Genre | Source | File/audio format | Number of Channels | Sample Rate | Bits per Second | Duration |
| ------|--------|----------|------------------|-------|---------|----------|--------------------|-------------|-----------------|----------|
|Violin concerto, in D Major , op.35| Isaac Sterns, Philedelphia Orchestra|Tchaikhovsky| Public Domain|Romantic| IMSLP |MP3|2 |48kHz|219 kbps|17:29|
|Swan Lake, Valse| Philedelphia Orchestra |Tchaikhovsky| Public Domain| Romantic| Internet Archive|MP3| 2|44.1kHz|198kbps|06:06|
|Serenade for Strings in C Major | University of Chicago symphony Orchestra|Tchaikovsky|Public Domain|Romantic|Internet Archive|MP3|2|44.1kHz|213kbps|10:42|

> **Task 2: Perform basic analysis of your 3 tracks in SonicVisualizer**

Below see a portion of my sonic visualiser output for my three chosen pieces .
* **TOP**: Waveform 
- **BOTTOM**: Spectogram

## Violin Concerto in D major. 
![concerto week 8 ss](https://github.com/user-attachments/assets/1dded657-5278-4555-8698-974c8b504bd1)


## Swan Lake: Valse

![valse week 8 ](https://github.com/user-attachments/assets/8b9502eb-fb9f-4d07-86d2-177b83b380cc)



## Serenade for Strings 

![serenade week 8](https://github.com/user-attachments/assets/c853dcfd-609c-4984-bf0e-3a861d9f54d4)


> **In 200 words (max), describe at least one advantage of a time-frequency analysis over a waveform-based analysis. Provide at least one example of the identified advantage by referencing a specific subpart of the output from step 1.**


One advantage on time frequency analysis over waveform-based analysis is that time- frequency analysis outputs and displays more ranges of information about the audio. The time-based frequency analysis shows areas of more intensity within the music and an overall outlook of the whole piece. While a waveform-based analysis only displays amplitude and volume, time frequency analysis shows the frequency and length and patterns of certain sound/pitch. This allows also for the movement and volumes of instruments to be identified, while this cannot be made out in a waveform-based analysis. 
To link this back to the outputs of my audio, you can see the amount of orange sections is significantly less on the first two pieces compared to Serenade for Strings (bottom picture) This is due to the more intensity in volume pitch and instruments compared to that of the concerto. the Serenade in Strings which contains very clear chord changes, we can clearly see this in the spectrogram with the placement of the orange sections towards the bottom and the length and height of the colour, also the patterns of pitch rising and falling across the different instruments and how this changes across the piece, which is one of the main advantages of a time-frequency analysis over a waveform based one.




# Week 9 

> **Task 1: Extract features**

In week 9s task i imported my three previously chosen recordings into sonic visualise. I then used sonic visualiser to create a spectogram, Mel Frequency cepstral Coefficiantrs and a Chromogram. See these displayed below.

see below my attached sonic visualiser outputs 
* **TOP**: Spectogram
- **MIDDLE**: Mel FRequency Cepstral 
+ **BOTTOM**: Chromogram


## Violin concerto 
![CONCERTO SCREENSHOT ](https://github.com/user-attachments/assets/1a4f5239-e4b1-4434-8948-956c61606a32)

## Swan Lake Valse 
![VALSE SCREENSHOT ](https://github.com/user-attachments/assets/4de96f58-7cda-4910-b9b6-e6694f54a356)


## Serenade for Strings 
![SERENADE SCREENSHOT ](https://github.com/user-attachments/assets/3e455943-d5e3-4a84-b1b2-57b950f93eba)






> **Task 2: Compute and Visualize features with histograms**

<img width="1131" alt="week 9" src="https://github.com/user-attachments/assets/8b124e27-543e-457a-9a72-1eded37ec2ec">




> **Highlight/discuss if the histograms capture significant differences between the tracks and if you expected this difference based on listening to the tracks**

Above I have plotted the histograms of the chorograms for each of my three pieces. On analysis of the three graphs, the histograms have not captured striking differences overall between the three tracks, however differences are still present. Broadly looking at them the Serenade for Strings has on average has a bigger range and more intensity of pitches throughout, compared to the violin concerto. The peaks of the histograms on the violin concerto are generally shorter and span across less pitches, this suggests there is possible many repeated motifs and melodies across the piece. This can be expected based on listening to the two tracks. However, this could also to of with quality of the recording. The quality of the Serenade for Strings and the Swan Lake was much than that of the Violin Concerto, hence sonic visualiser would maybe not be able to pick up on as many pitches and other musical information as the other two. However by the results of the chromogram before listening ,based on these results you can assume that all three pieces may have a slight similar sounds (genre) in terms of pitch and the general intensity and sound of the piece â€“ instruments and melody .



# Week 10 


>**Task 1: Similarity**

Below see my visualisations from the computations of my similarity matrix and my visualiser of the tracks in 2D. This is a similarity matrix between 7 sample tracks and then my three previous chosen tracks. Tracks 0 to 3 were classical and then tracks 4 to 6 were country and then my chosen tracks were tracks 7(Violin Concerto), 8(Valse) and 9(Serenade for Strings). However as my chosen songs were classical this meant tracks 0-3 and 7-9 were identified as being quite similar . See visualisations Below: 

## Similarity Matrices Left: C's & A's Right : All notes 
![week9picture 1 ](https://github.com/user-attachments/assets/c5ed630e-ae76-4f4f-aa1e-61000f709f4f)
![week9Picture2](https://github.com/user-attachments/assets/b2a313bf-1a9a-46af-8635-73fdb3992053)

## Visualiser of the tracks in 2D 

![classical](https://github.com/user-attachments/assets/b18a1a64-b06a-4350-b11c-4dfd7b5f3521)



> **Task 2: Transcription** 

In this task i exported the WAV file from my original transcription from week 2 and imported it into Sonic Visualiser. Using sonic visualiser i created a polyphonic transcription. This allowed me to export this out of sonic visualiser and back into MuseScore as an example of a transcription of audio to notation transcription. Below i have attached my before trancription and then the transcription after
## My Transcription Before:
<img src="https://github.com/user-attachments/assets/179994a2-6e3d-4873-9af7-a7f9b0e2f37e" alt="Piano Roll" width="300" height="400"><img src="https://github.com/user-attachments/assets/defc1613-a8c8-4d8e-b4a0-9c41bcaf01b1" alt="Piano Roll" width="300" height="400"><img src="https://github.com/user-attachments/assets/5094725a-9926-461b-9058-f457bd91af74" alt="Piano Roll" width="300" height="400">

## My Transcription After:

<img src="https://github.com/user-attachments/assets/b1108e3e-c4b8-4c53-a2ef-01bd421ea224" alt="Piano Roll" width="300" height="400"><img src="https://github.com/user-attachments/assets/b1108e3e-c4b8-4c53-a2ef-01bd421ea224" alt="Piano Roll" width="300" height="400">





 > **Display both images and compare the transcription, reflecting on its accuracy and identifying any information that has been lost.**

When comparing the two transcriptions it can be identified that MuseScore has not been able to identify the piano and the violin part as seperate parts, however the violin melodic line can be found. Also the key signature and many of the clefs are wron, however it has successfully transcribed many of the right rhythms. Pitch wise when playing them back the majority sound extremely similar to the original, however as becuase of the wrong key many of them are wrong. In conclusion this method cannot be a reliable method of transcribing audio and should be highly edited and reviewed first. 
The file of the transcription can be accessed [Here](https://github.com/rkirk903/MCA-2024/blob/master/Week10transcription.mscz)



















